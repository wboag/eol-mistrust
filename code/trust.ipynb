{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Generate Mistrust Scores for All Patients</h1>\n",
    "- Supervised Machine Learning (binary chartevents features) to predict whether \"noncompliance\" appears in the notes\n",
    "- Supervised Machine Learning (binary chartevents features) to predict whether the patient or family consents/declines autopsy\n",
    "- Off the shelf sentiment analysis of the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tqdm\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = psycopg2.connect(dbname ='mimic', user='wboag', host=\"/var/run/postgresql\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load Data from MIMIC</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-13 11:04:16\n",
      "2018-07-13 11:05:17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Baseline pain level</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>Bed Bath</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001</td>\n",
       "      <td>CHG Bath</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001</td>\n",
       "      <td>Currently experiencing pain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001</td>\n",
       "      <td>Education Barrier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id                        label value\n",
       "0   100001          Baseline pain level  None\n",
       "1   100001                     Bed Bath     1\n",
       "2   100001                     CHG Bath     1\n",
       "3   100001  Currently experiencing pain     0\n",
       "4   100001            Education Barrier  None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read interpersonal interaction variables from chartevents\n",
    "\n",
    "relevant_labels = '''\n",
    "Family Communication\n",
    "Follows Commands\n",
    "Education Barrier\n",
    "Education Learner\n",
    "Education Method\n",
    "Education Readiness\n",
    "Education Topic #1\n",
    "Education Topic #2\n",
    "Pain\n",
    "Pain Level\n",
    "Pain Level (Rest)\n",
    "Pain Assess Method\n",
    "Restraint\n",
    "Restraint Type\n",
    "Restraint (Non-violent)\n",
    "Restraint Ordered (Non-violent)\n",
    "Restraint Location\n",
    "Reason For Restraint\n",
    "Spiritual Support\n",
    "Support Systems\n",
    "State\n",
    "Behavior\n",
    "Behavioral State\n",
    "Reason For Restraint\n",
    "Stress\n",
    "Safety\n",
    "Safety Measures_U_1\n",
    "Family\n",
    "Patient/Family Informed\n",
    "Pt./Family Informed\n",
    "Health Care Proxy\n",
    "BATH                \n",
    "bath                \n",
    "Bath                \n",
    "Bed Bath            \n",
    "bed bath            \n",
    "bed bath            \n",
    "Bedbath             \n",
    "CHG Bath            \n",
    "Skin Care           \n",
    "Judgement           \n",
    "Family Meeting held \n",
    "Emotional / physical / sexual harm by partner or close relation\n",
    "Verbal Response\n",
    "Side Rails\n",
    "Orientation\n",
    "RSBI Deferred\n",
    "Richmond-RAS Scale\n",
    "Riker-SAS Scale\n",
    "Status and Comfort\n",
    "Teaching directed toward\n",
    "Consults\n",
    "Social work consult\n",
    "Sitter\n",
    "security\n",
    "safety\n",
    "headache\n",
    "hairwashed\n",
    "observer\n",
    "'''\n",
    "\n",
    "matches_text = []\n",
    "for rl in relevant_labels.split('\\n'):\n",
    "    rl = rl.strip()\n",
    "    if len(rl):\n",
    "        matches_text.append( \"LOWER(label) LIKE '%%%s%%'\" % rl.lower())\n",
    "matches = ' or '.join(matches_text)\n",
    "\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "chartevents_query = 'select distinct hadm_id,label,value from mimiciii.chartevents c JOIN mimiciii.d_items i on i.itemid=c.itemid where (%s)' % matches\n",
    "chartevents = pd.read_sql_query(chartevents_query, con)\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "\n",
    "chartevents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-13 11:05:17\n",
      "2018-07-13 11:06:46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>charttime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2117-9-11**]              ...</td>\n",
       "      <td>2117-09-17</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>[**2117-9-11**] 11:12 AM\\n CHEST (PA &amp; LAT)   ...</td>\n",
       "      <td>2117-09-11</td>\n",
       "      <td>2117-09-11 11:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Admission Date:  [**2150-4-17**]              ...</td>\n",
       "      <td>2150-04-21</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>ECG</td>\n",
       "      <td>Sinus rhythm\\nProlonged QT interval is nonspec...</td>\n",
       "      <td>2150-04-17</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100003</td>\n",
       "      <td>Echo</td>\n",
       "      <td>PATIENT/TEST INFORMATION:\\nIndication: Left ve...</td>\n",
       "      <td>2150-04-18</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id           category  \\\n",
       "0   100001  Discharge summary   \n",
       "1   100001          Radiology   \n",
       "2   100003  Discharge summary   \n",
       "3   100003                ECG   \n",
       "4   100003               Echo   \n",
       "\n",
       "                                                text  chartdate  \\\n",
       "0  Admission Date:  [**2117-9-11**]              ... 2117-09-17   \n",
       "1  [**2117-9-11**] 11:12 AM\\n CHEST (PA & LAT)   ... 2117-09-11   \n",
       "2  Admission Date:  [**2150-4-17**]              ... 2150-04-21   \n",
       "3  Sinus rhythm\\nProlonged QT interval is nonspec... 2150-04-17   \n",
       "4  PATIENT/TEST INFORMATION:\\nIndication: Left ve... 2150-04-18   \n",
       "\n",
       "            charttime  \n",
       "0                 NaT  \n",
       "1 2117-09-11 11:12:00  \n",
       "2                 NaT  \n",
       "3                 NaT  \n",
       "4                 NaT  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Notes\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) \n",
    "notes_query = \\\n",
    "\"\"\"\n",
    "select distinct n.hadm_id,n.category,n.text,n.chartdate,n.charttime\n",
    "from mimiciii.noteevents n\n",
    "where iserror IS NULL --this is null in mimic 1.4, rather than empty space\n",
    "and hadm_id IS NOT NULL\n",
    ";\n",
    "\"\"\"\n",
    "notes = pd.read_sql_query(notes_query, con)\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime()) \n",
    "\n",
    "notes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Extract Features and Labels</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54510/54510 [04:45<00:00, 190.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract features from chartevents\n",
    "\n",
    "chartevents_features = {}\n",
    "for hadm_id,rows in tqdm.tqdm(chartevents.groupby('hadm_id')):\n",
    "    feats = {}\n",
    "    for i,row in rows.iterrows():\n",
    "        label = row.label.lower()\n",
    "        \n",
    "        if row.value is None:\n",
    "            val = 'none'\n",
    "        else:\n",
    "            val = row.value.lower()\n",
    "        \n",
    "        \n",
    "        if 'reason for restraint' in label:       \n",
    "            \n",
    "            if (val == 'not applicable') or (val == 'none'):\n",
    "                val = 'none'\n",
    "            elif ('threat' in val) or ('acute risk of' in val):\n",
    "                val = 'threat of harm'\n",
    "            elif ('confusion' in val) or ('delirium' in val) or (val == 'impaired judgment') or (val == 'sundowning'):\n",
    "                val = 'confusion/delirium'\n",
    "            elif ('occurence' in val) or (val == 'severe physical agitation') or (val == 'violent/self des'):\n",
    "                val = 'prescence of violence'\n",
    "            elif (val == 'ext/txinterfere') or (val == 'protection of lines and tubes') or (val == 'treatment interference'):\n",
    "                val = 'treatment interference'\n",
    "            elif 'risk for fall' in val:\n",
    "                val = 'risk for falls'\n",
    "            else:\n",
    "                val = val\n",
    "            \n",
    "            feats[('reason for restraint', val)] = 1\n",
    "\n",
    "        elif 'restraint location' in label:\n",
    "                \n",
    "            if val == 'none':\n",
    "                val = 'none'\n",
    "            elif '4 point rest' in val:\n",
    "                val = '4 point restraint'\n",
    "            else:\n",
    "                val = 'some restraint'\n",
    "            \n",
    "            feats[('restraint location', val)] = 1\n",
    "\n",
    "        elif 'restraint device' in label:\n",
    "                \n",
    "            if 'sitter' in val:\n",
    "                val = 'sitter'\n",
    "            elif 'limb' in val:\n",
    "                val = 'limb'\n",
    "            else:\n",
    "                val = val\n",
    "            \n",
    "            feats[('restraint device', val)] = 1\n",
    "            \n",
    "        elif 'bath' in label:\n",
    "            if 'part' in label:\n",
    "                val = 'partial'\n",
    "            elif 'self' in val:\n",
    "                val = 'self'\n",
    "            elif 'refused' in val:\n",
    "                val = 'refused'\n",
    "            elif 'shave' in val:\n",
    "                val = 'shave'\n",
    "            elif 'hair' in val:\n",
    "                val = 'hair'\n",
    "            elif 'none' in val:\n",
    "                val = 'none'\n",
    "            else:\n",
    "                val = 'done'\n",
    "            \n",
    "            feats[('bath', val)] = 1\n",
    "\n",
    "        elif label in ['behavior', 'behavioral state']:\n",
    "            #feats[('behavior', val)] = 1\n",
    "            pass\n",
    "            \n",
    "        elif label.startswith('pain level'):\n",
    "            feats[('pain level', val)] = 1\n",
    "            \n",
    "        elif label.startswith('pain management'):\n",
    "            #feats[('pain management', val)] = 1\n",
    "            pass\n",
    "        elif label.startswith('pain type'):\n",
    "            #feats[('pain type', val)] = 1\n",
    "            pass\n",
    "        elif label.startswith('pain cause'):\n",
    "            #feats[('pain cause', val)] = 1\n",
    "            pass\n",
    "        elif label.startswith('pain location'):\n",
    "            #feats[('pain location', val)] = 1\n",
    "            pass\n",
    "            \n",
    "        elif label.startswith('education topic'):\n",
    "            feats[('education topic', val)] = 1\n",
    "\n",
    "        elif label.startswith('safety measures'):\n",
    "            feats[('safety measures', val)] = 1\n",
    "            \n",
    "        elif label.startswith('side rails'):\n",
    "            feats[('side rails', val)] = 1\n",
    "    \n",
    "        elif label.startswith('status and comfort'):\n",
    "            feats[('status and comfort', val)] = 1\n",
    "\n",
    "        elif 'informed' in label:\n",
    "            feats[('informed', val)] = 1        \n",
    "        else:\n",
    "\n",
    "            if type(row.value) == type(''):\n",
    "                # extract phrase\n",
    "                featname = (row.label.lower(), row.value.lower())\n",
    "                value = 1.0\n",
    "                feats[featname] = value\n",
    "            elif row.value is None:\n",
    "                featname = (row.label.lower(),'none')\n",
    "                value = 1.0\n",
    "                feats[featname] = value\n",
    "            else: \n",
    "                featname = (row.label.lower(),)\n",
    "                value = value\n",
    "                feats[featname] = value\n",
    "                pass\n",
    "            \n",
    "    \n",
    "    chartevents_features[hadm_id] = feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58361/58361 [00:17<00:00, 3307.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients labeled as    trustful: 54030\n",
      "patients labeled as mistrustful: 484\n"
     ]
    }
   ],
   "source": [
    "# LABEL: noncompliance in notes\n",
    "\n",
    "mistrust_ids = []\n",
    "for hadm_id,rows in tqdm.tqdm(notes.groupby('hadm_id')):\n",
    "    # This is customizable to various note-based definitions of what to look for\n",
    "    mistrust = False\n",
    "    for text in rows.text.values:\n",
    "        if 'noncompliant' in text.lower():\n",
    "            mistrust = True\n",
    "            \n",
    "    # add the ID\n",
    "    if mistrust:\n",
    "        mistrust_ids.append(hadm_id)\n",
    "\n",
    "        \n",
    "# binary labels\n",
    "trust_labels_noncompliance = {hadm_id:'trust' for hadm_id in chartevents['hadm_id'].values}\n",
    "for hadm_id in mistrust_ids:\n",
    "    trust_labels_noncompliance[int(hadm_id)] = 'mistrust'\n",
    "    \n",
    "print 'patients labeled as    trustful:', len([y for y in trust_labels_noncompliance.values() if y=='trust'   ])\n",
    "print 'patients labeled as mistrustful:', len([y for y in trust_labels_noncompliance.values() if y=='mistrust'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58361/58361 [00:31<00:00, 1841.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients labeled as    trustful: 739\n",
      "patients labeled as mistrustful: 270\n"
     ]
    }
   ],
   "source": [
    "# LABEL: whether patient got autopsy\n",
    "\n",
    "autopsy_consent = []\n",
    "autopsy_decline = []\n",
    "for hadm_id,rows in tqdm.tqdm(notes.groupby('hadm_id')):\n",
    "    consented = False\n",
    "    declined = False\n",
    "    for text in rows.text.values:\n",
    "        for line in text.lower().split('\\n'):\n",
    "            if 'autopsy' in line:\n",
    "                if 'decline' in line:\n",
    "                    declined = True\n",
    "                if 'not consent' in line:\n",
    "                    declined = True\n",
    "                if 'refuse' in line:\n",
    "                    declined = True\n",
    "                if 'denied' in line:\n",
    "                    declined = True\n",
    "                    \n",
    "                if 'consent' in line:\n",
    "                    consented = True\n",
    "                if 'agree' in line:\n",
    "                    consented = True\n",
    "                if 'request' in line:\n",
    "                    consented = True\n",
    "                \n",
    "    # probably some \"declined donation but consented to autopsy\" or something confusing. just ignore hard cases\n",
    "    if consented and declined:\n",
    "        continue\n",
    "\n",
    "    if consented:\n",
    "        autopsy_consent.append(hadm_id)\n",
    "    if declined:\n",
    "        autopsy_decline.append(hadm_id)\n",
    "        \n",
    "# binary labels\n",
    "trust_labels_autopsy = {}\n",
    "for hadm_id in autopsy_consent:\n",
    "    trust_labels_autopsy[int(hadm_id)] = 'mistrust'\n",
    "for hadm_id in autopsy_decline:\n",
    "    trust_labels_autopsy[int(hadm_id)] = 'trust'\n",
    "    \n",
    "print 'patients labeled as    trustful:', len([y for y in trust_labels_autopsy.values() if y=='trust'   ])\n",
    "print 'patients labeled as mistrustful:', len([y for y in trust_labels_autopsy.values() if y=='mistrust'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Supervised Learning to Classify Trust-based Outcomes</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful ML functions\n",
    "\n",
    "def data_split(ids, ratio=0.7):\n",
    "    random.shuffle(ids)\n",
    "    train = ids[:int(len(ids)*ratio) ]\n",
    "    test  = ids[ int(len(ids)*ratio):]\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def compute_stats(task, pred, P, ref, labels_map):\n",
    "    scores = P[:,1] - P[:,0]\n",
    "    res = compute_stats_binary(    task, pred, scores, ref, labels_map)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def compute_stats_binary(task, pred, P, ref, labels):\n",
    "    # santiy check\n",
    "    assert all(map(int,P>0) == pred)\n",
    "\n",
    "    V = [0,1]\n",
    "    n = len(V)\n",
    "    assert n==2, 'sorry, must be exactly two labels (how else would we do AUC?)'\n",
    "    conf = np.zeros((n,n), dtype='int32')\n",
    "    for p,r in zip(pred,ref):\n",
    "        conf[p][r] += 1\n",
    "\n",
    "    print conf\n",
    "    print\n",
    "    \n",
    "    tp = conf[1,1]\n",
    "    tn = conf[0,0]\n",
    "    fp = conf[1,0]\n",
    "    fn = conf[0,1]\n",
    "\n",
    "    precision   = tp / (tp + fp + 1e-9)\n",
    "    recall      = tp / (tp + fn + 1e-9)\n",
    "    sensitivity = tp / (tp + fn + 1e-9)\n",
    "    specificity = tn / (tn + fp + 1e-9)\n",
    "\n",
    "    f1 = (2*precision*recall) / (precision+recall+1e-9)\n",
    "\n",
    "    accuracy = (tp+tn) / (tp+tn+fp+fn + 1e-9)\n",
    "    \n",
    "    print '\\tspecificity %.3f' % specificity\n",
    "    print '\\tsensitivty: %.3f' % sensitivity\n",
    "\n",
    "    # AUC\n",
    "    if len(set(ref)) == 2:\n",
    "        auc = sklearn.metrics.roc_auc_score(ref, P)\n",
    "        print '\\t\\tauc:        %.3f' % auc\n",
    "\n",
    "    print '\\taccuracy:   %.3f' % accuracy\n",
    "    print '\\tprecision:  %.3f' % precision\n",
    "    print '\\trecall:     %.3f' % recall\n",
    "    print '\\tf1:         %.3f' % f1\n",
    "    \n",
    "    res = {'accuracy':accuracy, 'precision':precision, 'recall':recall, 'f1':f1, \n",
    "           'auc':auc, 'sensitivity':sensitivity, 'specificity':specificity}\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def classification_results(svm, labels_map, X, Y, task):\n",
    "    # for AUC\n",
    "    P_ = svm.decision_function(X)\n",
    "\n",
    "    # sklearn has stupid-ass changes in API when doing binary classification. make it conform to 3+\n",
    "    if len(labels_map)==2:\n",
    "        m = X.shape[0]\n",
    "        P = np.zeros((m,2))\n",
    "        P[:,0] = -P_\n",
    "        P[:,1] =  P_\n",
    "    else:\n",
    "        P = P_\n",
    "\n",
    "    train_pred = P.argmax(axis=1)\n",
    "\n",
    "    # what is the predicted vocab without the dummy label?\n",
    "    V = labels_map.keys()\n",
    "\n",
    "    print task\n",
    "    res = compute_stats(task, train_pred, P, Y, labels_map)\n",
    "    print '\\n'\n",
    "    return res\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features: 620\n"
     ]
    }
   ],
   "source": [
    "# Fit vectorizer for chartevents features\n",
    "vect = DictVectorizer()\n",
    "vect.fit(chartevents_features.values())\n",
    "print 'num_features:', len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display informative features\n",
    "\n",
    "def classification_analyze(task, vect, clf, labels_map, num_feats=10):\n",
    "    ind2feat =  { i:f for f,i in vect.vocabulary_.items() }\n",
    "\n",
    "    labels = [label for label,i in sorted(labels_map.items(), key=lambda t:t[1])]\n",
    "    coef_ = clf.coef_\n",
    "    \n",
    "    informative_feats = np.argsort(coef_)\n",
    "\n",
    "    neg_features = informative_feats[0,:num_feats ]\n",
    "    pos_features = informative_feats[0,-num_feats:]\n",
    "    \n",
    "    # display what each feature is\n",
    "    print 'POS %s' % label\n",
    "    for feat in reversed(pos_features):\n",
    "        val = coef_[0,feat]\n",
    "        word = ind2feat[feat]\n",
    "        if val > 1e-4:\n",
    "            print '\\t%-25s: %7.4f' % (word,val)\n",
    "        else:\n",
    "            break\n",
    "    print 'NEG %s' % label\n",
    "    for feat in reversed(neg_features):\n",
    "        val = coef_[0,feat]\n",
    "        word = ind2feat[feat]\n",
    "        if -val > 1e-4:\n",
    "            print '\\t%-25s: %7.4f' % (word,val)\n",
    "        else:\n",
    "            continue\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trust': 0, 'mistrust': 1}\n"
     ]
    }
   ],
   "source": [
    "# vectorize task-specific labels\n",
    "trust_Y_vect = {'mistrust': 1, 'trust': 0}\n",
    "print trust_Y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients: 54510\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False)\n",
      "train: noncompliance\n",
      "[[37817   340]\n",
      " [    0     0]]\n",
      "\n",
      "\tspecificity 1.000\n",
      "\tsensitivty: 0.000\n",
      "\t\tauc:        0.723\n",
      "\taccuracy:   0.991\n",
      "\tprecision:  0.000\n",
      "\trecall:     0.000\n",
      "\tf1:         0.000\n",
      "\n",
      "\n",
      "test:  noncompliance\n",
      "[[16213   140]\n",
      " [    0     0]]\n",
      "\n",
      "\tspecificity 1.000\n",
      "\tsensitivty: 0.000\n",
      "\t\tauc:        0.675\n",
      "\taccuracy:   0.991\n",
      "\tprecision:  0.000\n",
      "\trecall:     0.000\n",
      "\tf1:         0.000\n",
      "\n",
      "\n",
      "POS mistrust\n",
      "\t('riker-sas scale', 'agitated'):  0.6963\n",
      "\t('support systems', 'relative'):  0.2188\n",
      "\t('headache', 'not present'):  0.2151\n",
      "\t('riker-sas scale', 'sedated'):  0.1853\n",
      "\t('pain level', '0-none') :  0.1653\n",
      "\t('health care proxy', 'no'):  0.1567\n",
      "\t('education topic', 'medications'):  0.1424\n",
      "\t('social work consult', '1'):  0.1014\n",
      "\t('side rails', 'all rails up (restraint)'):  0.0997\n",
      "\t('verbal response', '4 confused'):  0.0694\n",
      "\t('reason for restraint', 'confusion/delirium'):  0.0290\n",
      "\t('safety measures', 'clear, firm limit setting'):  0.0120\n",
      "\t('riker-sas scale', 'calm/cooperative'):  0.0094\n",
      "\t('education barrier', 'altered loc'):  0.0032\n",
      "\t('education barrier', 'anxiety'):  0.0019\n",
      "NEG mistrust\n",
      "\t('education readiness', 'yes'): -0.0412\n",
      "\t('pain present', 'no')   : -0.0614\n",
      "\t('pain present', 'yes')  : -0.0654\n",
      "\t('pain assess method', 'change in vitals'): -0.0801\n",
      "\t('is the spokesperson the health care proxy', '1'): -0.0840\n",
      "\t('family communication', 'family talked to rn'): -0.1144\n",
      "\t('support systems', 'children'): -0.1250\n",
      "\t('skin care', 'done')    : -0.1368\n",
      "\t('family communication', 'family visited'): -0.1389\n",
      "\t('verbal response', '1.0 et/trach'): -0.1415\n",
      "\t('support systems', 'spouse'): -0.1453\n",
      "\t('pain assess method', 'non-verbal cues'): -0.1925\n",
      "\t('stress', 'none')       : -0.2947\n",
      "\t('richmond-ras scale', ' 0  alert and calm'): -0.4142\n",
      "\t('state', 'alert')       : -0.9068\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFIER: noncompliance\n",
    "\n",
    "noncompliance_cohort = list(set(trust_labels_noncompliance.keys()) & set(chartevents['hadm_id'].values))\n",
    "print 'patients:', len(noncompliance_cohort)\n",
    "\n",
    "# train/test split\n",
    "noncompliance_train_ids, noncompliance_test_ids = data_split(noncompliance_cohort)\n",
    "\n",
    "# select pre-computed features\n",
    "noncompliance_train_features = [chartevents_features[hadm_id] for hadm_id in noncompliance_train_ids]\n",
    "noncompliance_test_features  = [chartevents_features[hadm_id] for hadm_id in noncompliance_test_ids ]\n",
    "\n",
    "# vectorize features\n",
    "noncompliance_train_X = vect.transform(noncompliance_train_features)\n",
    "noncompliance_test_X  = vect.transform(noncompliance_test_features)\n",
    "\n",
    "# select labels\n",
    "noncompliance_train_Y = [trust_Y_vect[trust_labels_noncompliance[hadm_id]] for hadm_id in noncompliance_train_ids]\n",
    "noncompliance_test_Y  = [trust_Y_vect[trust_labels_noncompliance[hadm_id]] for hadm_id in noncompliance_test_ids ]\n",
    "\n",
    "# fit model\n",
    "noncompliance_svm = LogisticRegression(C=0.1, penalty='l1', tol=0.01)\n",
    "noncompliance_svm.fit(noncompliance_train_X, noncompliance_train_Y)\n",
    "print noncompliance_svm\n",
    "\n",
    "# evaluate model\n",
    "classification_results(noncompliance_svm, trust_Y_vect, noncompliance_train_X, noncompliance_train_Y, 'train: noncompliance')\n",
    "classification_results(noncompliance_svm, trust_Y_vect,  noncompliance_test_X,  noncompliance_test_Y, 'test:  noncompliance')\n",
    "\n",
    "# most informative features\n",
    "classification_analyze('noncompliance', vect, noncompliance_svm, trust_Y_vect, num_feats=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients: 997\n",
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.01,\n",
      "          verbose=0, warm_start=False)\n",
      "train: autopsy\n",
      "[[515 182]\n",
      " [  0   0]]\n",
      "\n",
      "\tspecificity 1.000\n",
      "\tsensitivty: 0.000\n",
      "\t\tauc:        0.627\n",
      "\taccuracy:   0.739\n",
      "\tprecision:  0.000\n",
      "\trecall:     0.000\n",
      "\tf1:         0.000\n",
      "\n",
      "\n",
      "test:  autopsy\n",
      "[[216  84]\n",
      " [  0   0]]\n",
      "\n",
      "\tspecificity 1.000\n",
      "\tsensitivty: 0.000\n",
      "\t\tauc:        0.530\n",
      "\taccuracy:   0.720\n",
      "\tprecision:  0.000\n",
      "\trecall:     0.000\n",
      "\tf1:         0.000\n",
      "\n",
      "\n",
      "POS mistrust\n",
      "\t('restraints evaluated', 'restraintreapply'):  0.0858\n",
      "\t('orientation', 'oriented x 3'):  0.0685\n",
      "\t('orientation', 'oriented x 2'):  0.0221\n",
      "NEG mistrust\n",
      "\t('education readiness', 'no'): -0.0323\n",
      "\t('education method', 'explanation'): -0.0354\n",
      "\t('support systems', 'children'): -0.0438\n",
      "\t('safety measures', 'call light within reach'): -0.0451\n",
      "\t('education barrier', 'altered loc'): -0.0455\n",
      "\t('safety measures', 'bed locked in low position'): -0.0936\n",
      "\t('side rails', '3 rails up'): -0.0963\n",
      "\t('family communication', 'family talked to md'): -0.1245\n",
      "\t('safety measures', 'adequate lighting'): -0.1314\n",
      "\t('pain present', 'no')   : -0.2009\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CLASSIFIER: autopsy\n",
    "\n",
    "autopsy_cohort = list(set(trust_labels_autopsy.keys()) & set(chartevents['hadm_id'].values))\n",
    "print 'patients:', len(autopsy_cohort)\n",
    "\n",
    "# train/test split\n",
    "autopsy_train_ids, autopsy_test_ids = data_split(autopsy_cohort)\n",
    "\n",
    "# select pre-computed features\n",
    "autopsy_train_features = [chartevents_features[hadm_id] for hadm_id in autopsy_train_ids]\n",
    "autopsy_test_features  = [chartevents_features[hadm_id] for hadm_id in autopsy_test_ids ]\n",
    "\n",
    "# vectorize features\n",
    "autopsy_train_X = vect.transform(autopsy_train_features)\n",
    "autopsy_test_X  = vect.transform(autopsy_test_features)\n",
    "\n",
    "# select labels\n",
    "autopsy_train_Y = [trust_Y_vect[trust_labels_autopsy[hadm_id]] for hadm_id in autopsy_train_ids]\n",
    "autopsy_test_Y  = [trust_Y_vect[trust_labels_autopsy[hadm_id]] for hadm_id in autopsy_test_ids ]\n",
    "\n",
    "# fit model\n",
    "autopsy_svm = LogisticRegression(C=0.1, penalty='l1', tol=0.01)\n",
    "autopsy_svm.fit(autopsy_train_X, autopsy_train_Y)\n",
    "print autopsy_svm\n",
    "\n",
    "# evaluate model\n",
    "classification_results(autopsy_svm, trust_Y_vect, autopsy_train_X, autopsy_train_Y, 'train: autopsy')\n",
    "classification_results(autopsy_svm, trust_Y_vect,  autopsy_test_X,  autopsy_test_Y, 'test:  autopsy')\n",
    "\n",
    "# most informative features\n",
    "classification_analyze('trust', vect, autopsy_svm, trust_Y_vect, num_feats=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: noncompliance scores\n",
      "DONE: autopsy scores\n"
     ]
    }
   ],
   "source": [
    "# Predict scores for all patients and save to file\n",
    "\n",
    "# ordering of all chartevents features\n",
    "chartevents_ids = set(chartevents['hadm_id'].values)\n",
    "chartevents_X = vect.transform([chartevents_features[hadm_id] for hadm_id in chartevents_ids])\n",
    "\n",
    "# Save ranking (i.e. confidence from trust classifier) of all patients on the noncompliance metric\n",
    "with open('../data/mistrust_noncompliant.pkl', 'wb') as f:\n",
    "    noncompliance_scores = dict(zip(chartevents_ids,noncompliance_svm.decision_function(chartevents_X)))\n",
    "    pickle.dump(noncompliance_scores, f)\n",
    "print 'DONE: noncompliance scores'\n",
    "\n",
    "# Save ranking (i.e. confidence from trust classifier) of all patients on the autopsy metric\n",
    "with open('../data/mistrust_autopsy.pkl', 'wb') as f:\n",
    "    autopsy_scores = dict(zip(chartevents_ids,autopsy_svm.decision_function(chartevents_X)))\n",
    "    pickle.dump(autopsy_scores, f)\n",
    "print 'DONE: autopsy scores'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sentiment Analysis as Mistrust Proxy</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Analysis\n",
    "from pattern.en import sentiment\n",
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "datadir = '/scratch/wboag/2018/iatrophobia/sequence/data/readable/all/'\n",
    "\n",
    "sentiments = {}\n",
    "#for hadm_id in tqdm.tqdm(bw_eol_cohort['hadm_id'].values):\n",
    "for name in tqdm.tqdm(os.listdir(datadir)):\n",
    "    #filename = '/scratch/wboag/2018/iatrophobia/sequence/data/readable/all/%s.txt' % hadm_id\n",
    "    filename = os.path.join(datadir, name)\n",
    "    hadm_id = int(name.split('.')[0])\n",
    "    if not os.path.exists(filename):\n",
    "        continue\n",
    "        \n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read().split('================================================================================')[1]\n",
    "        \n",
    "    # Returns a (polarity, subjectivity)-tuple.\n",
    "    sa = sentiment(text.split())\n",
    "    #sa = sentiment(text)\n",
    "    #print sa\n",
    "    sentiments[hadm_id] = sa[0]\n",
    "    #break\n",
    "\n",
    "scores = np.array(sentiments.values())\n",
    "mu = scores.mean()\n",
    "std = scores.std()\n",
    "sentiments = {k:-(v-mu)/std for k,v in sentiments.items()}\n",
    "    \n",
    "print 'sa:', len(sentiments)\n",
    "\n",
    "with open('../data/neg_sentiment.pkl', 'wb') as f:\n",
    "    pickle.dump(sentiments, f)\n",
    "print 'DONE: negative sentiment scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

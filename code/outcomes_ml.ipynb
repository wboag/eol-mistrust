{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Outcomes Using Trust Features</h1>\n",
    "Does performance improve for tasks (code status, leaving AMA, and in-hosp mortality) when adding mistrust features on top of demographics? \n",
    "Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from time import gmtime, strftime\n",
    "import tqdm\n",
    "\n",
    "con = psycopg2.connect(dbname ='mimic', user='wboag', host=\"/var/run/postgresql\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-05 04:15:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46121it [00:06, 6879.72it/s]\n"
     ]
    }
   ],
   "source": [
    "print strftime(\"%Y-%m-%d %H:%M:%S\", gmtime())\n",
    "\n",
    "# LABEL: code status\n",
    "\n",
    "code_query = \"select distinct hadm_id,label,value from mimiciii.chartevents c JOIN mimiciii.d_items i on i.itemid=c.itemid where label = 'Code Status'\"\n",
    "code_status = pd.read_sql_query(code_query, con)\n",
    "\n",
    "# binary labels\n",
    "code_labels = {}\n",
    "for i,row in tqdm.tqdm(code_status.iterrows()):\n",
    "    if row.value is not None:\n",
    "        if ('DNR' in row.value) or ('DNI' in row.value) or ('Comfort' in row.value) or ('Do Not' in row.value):\n",
    "            label = 'DNR/CMO'\n",
    "        elif (row.value == 'Full Code') or (row.value == 'Full code'):\n",
    "            label = 'Full Code'\n",
    "    code_labels[row.hadm_id] = label\n",
    "    \n",
    "#ode_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['DNR / DNI', 'DNR (do not resuscitate)', 'Other/Remarks', 'DNI (do not intubate)', 'Comfort measures only', 'Do Not Intubate', None, 'Full code', 'Full Code', 'Comfort Measures', 'CPR Not Indicate', 'Do Not Resuscita'])\n"
     ]
    }
   ],
   "source": [
    "print set(code_status['value'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hadm -> race\n",
    "import tqdm\n",
    "\n",
    "def normalize_race(race):\n",
    "    if 'HISPANIC' in race:\n",
    "        return 'Hispanic'\n",
    "    if 'SOUTH AMERICAN' in race:\n",
    "        return 'Hispanic'\n",
    "    if 'AMERICAN INDIAN' in race:\n",
    "        return 'Native American'\n",
    "    if 'ASIAN' in race:\n",
    "        return 'Asian'\n",
    "    if 'BLACK' in race:\n",
    "        return 'Black'\n",
    "    if 'WHITE' in race:\n",
    "        return 'White'\n",
    "    return 'Other'\n",
    "\n",
    "def normalize_insurance(insurance):\n",
    "    if insurance in ['Medicare', 'Medicaid', 'Government']:\n",
    "        return 'Public'\n",
    "    else:\n",
    "        return insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58976it [00:05, 10526.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# LABEL: left hospital against medical advice\n",
    "\n",
    "# query for discharge info\n",
    "discharge_query = 'SELECT distinct hadm_id,discharge_location FROM mimiciii.admissions'\n",
    "discharge = pd.read_sql_query(discharge_query, con)\n",
    "\n",
    "# binary labels\n",
    "ama_labels = {}\n",
    "for i,row in tqdm.tqdm(discharge.iterrows()):\n",
    "    if row.discharge_location == 'LEFT AGAINST MEDICAL ADVI':\n",
    "        label = 'AMA'\n",
    "    else:\n",
    "        label = 'compliant'\n",
    "    ama_labels[row.hadm_id] = label\n",
    "\n",
    "#discharge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58976it [00:04, 11829.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# LABEL: in-hospital mortality\n",
    "\n",
    "# query for discharge info\n",
    "mortality_query = 'SELECT distinct hadm_id,hospital_expire_flag FROM mimiciii.admissions'\n",
    "mortality = pd.read_sql_query(mortality_query, con)\n",
    "\n",
    "# binary labels\n",
    "mortality_labels = {}\n",
    "for i,row in tqdm.tqdm(mortality.iterrows()):\n",
    "    if row.hospital_expire_flag:\n",
    "        label = 'deceased'\n",
    "    else:\n",
    "        label = 'survived'\n",
    "    mortality_labels[row.hadm_id] = label\n",
    "\n",
    "#mortality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def data_split(ids, ratio=0.6):\n",
    "    random.shuffle(ids)\n",
    "    train = ids[:int(len(ids)*ratio) ]\n",
    "    test  = ids[ int(len(ids)*ratio):]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write informative features code\n",
    "\n",
    "def analyze(task, vect, clf, count_top=False):\n",
    "\n",
    "    ind2feat =  { i:f for f,i in vect.vocabulary_.items() }\n",
    "\n",
    "    # create a 2-by-m matrix for biary, rather than relying on 1-p bullshit\n",
    "    coef_ = clf.coef_\n",
    "    \n",
    "    # most informative features\n",
    "    #\"\"\"\n",
    "    print task\n",
    "    informative_feats = np.argsort(coef_)\n",
    "    \n",
    "    if len(informative_feats.shape) == 2:\n",
    "        informative_feats = informative_feats[0,:]\n",
    "        coef_ = coef_[0,:]\n",
    "        \n",
    "    #'''\n",
    "    # display what each feature is\n",
    "    for feat in reversed(informative_feats):\n",
    "        val = coef_[feat]\n",
    "\n",
    "        word = ind2feat[feat]\n",
    "        print '\\t%-25s: %7.4f' % (word,val)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "import pylab as plt\n",
    "\n",
    "\n",
    "def compute_stats(task, pred, P, ref, labels_map, verbose):\n",
    "    if len(labels_map) == 2:\n",
    "        scores = P[:,1] - P[:,0]\n",
    "        res = compute_stats_binary(    task, pred, scores, ref, labels_map, verbose)\n",
    "    else:\n",
    "        res = compute_stats_multiclass(task, pred, P     , ref, labels_map, verbose)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def compute_stats_binary(task, pred, P, ref, labels, verbose):\n",
    "    # santiy check\n",
    "    assert all(map(int,P>0) == pred)\n",
    "\n",
    "    V = [0,1]\n",
    "    n = len(V)\n",
    "    assert n==2, 'sorry, must be exactly two labels (how else would we do AUC?)'\n",
    "    conf = np.zeros((n,n), dtype='int32')\n",
    "    for p,r in zip(pred,ref):\n",
    "        conf[p][r] += 1\n",
    "\n",
    "    if verbose:\n",
    "        print conf\n",
    "        print\n",
    "    \n",
    "    tp = conf[1,1]\n",
    "    tn = conf[0,0]\n",
    "    fp = conf[1,0]\n",
    "    fn = conf[0,1]\n",
    "\n",
    "    precision   = tp / (tp + fp + 1e-9)\n",
    "    recall      = tp / (tp + fn + 1e-9)\n",
    "    sensitivity = tp / (tp + fn + 1e-9)\n",
    "    specificity = tn / (tn + fp + 1e-9)\n",
    "\n",
    "    f1 = (2*precision*recall) / (precision+recall+1e-9)\n",
    "\n",
    "    tpr =  true_positive_rate(pred, ref)\n",
    "    fpr = false_positive_rate(pred, ref)\n",
    "\n",
    "    accuracy = (tp+tn) / (tp+tn+fp+fn + 1e-9)\n",
    "    \n",
    "    if verbose:\n",
    "        print '\\tspecificity %.3f' % specificity\n",
    "        print '\\tsensitivty: %.3f' % sensitivity\n",
    "\n",
    "    # AUC\n",
    "    if len(set(ref)) == 2:\n",
    "        auc = sklearn.metrics.roc_auc_score(ref, P)\n",
    "        if verbose: print '\\t\\tauc:        %.3f' % auc\n",
    "\n",
    "    if verbose:\n",
    "        print '\\taccuracy:   %.3f' % accuracy\n",
    "        print '\\tprecision:  %.3f' % precision\n",
    "        print '\\trecall:     %.3f' % recall\n",
    "        print '\\tf1:         %.3f' % f1\n",
    "        print '\\tTPR:        %.3f' % tpr\n",
    "        print '\\tFPR:        %.3f' % fpr\n",
    "\n",
    "        print 'TODO: VIZ THE ROC CURVE'\n",
    "\n",
    "    res = {'accuracy':accuracy, 'precision':precision, 'recall':recall, 'f1':f1, 'tpr':tpr,\n",
    "           'fpr':fpr, 'auc':auc, 'sensitivity':sensitivity, 'specificity':specificity}\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def compute_stats_multiclass(task, pred, P, ref, labels_map):\n",
    "    # santiy check\n",
    "    assert all(map(int,P.argmax(axis=1)) == pred)\n",
    "\n",
    "    # get rid of that final prediction dimension\n",
    "    #pred = pred[1:]\n",
    "    #ref  =  ref[1:]\n",
    "\n",
    "    V = set(range(len(labels_map)))\n",
    "    n = max(V)+1\n",
    "    conf = np.zeros((n,n), dtype='int32')\n",
    "    for p,r in zip(pred,ref):\n",
    "        conf[p][r] += 1\n",
    "\n",
    "\n",
    "    labels = [label for label,i in sorted(labels_map.items(), key=lambda t:t[1])]\n",
    "\n",
    "\n",
    "    print conf\n",
    "    print\n",
    "    \n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    print '\\t prec  rec    f1   label'\n",
    "    for i in range(n):\n",
    "        label = labels[i]\n",
    "\n",
    "        tp = conf[i,i]\n",
    "        pred_pos = conf[i,:].sum()\n",
    "        ref_pos  = conf[:,i].sum()\n",
    "\n",
    "        precision   = tp / (pred_pos + 1e-9)\n",
    "        recall      = tp / (ref_pos + 1e-9)\n",
    "        f1 = (2*precision*recall) / (precision+recall+1e-9)\n",
    "\n",
    "        print '\\t%.3f %.3f %.3f %s' % (precision,recall,f1,label)\n",
    "\n",
    "        # Save info\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    avg_precision = sum(precisions) / len(precisions)\n",
    "    avg_recall    = sum(recalls   ) / len(recalls   )\n",
    "    avg_f1        = sum(f1s       ) / len(f1s       )\n",
    "    print '\\t--------------------------'\n",
    "    print '\\t%.3f %.3f %.3f avg' % (avg_precision,avg_recall,avg_f1)\n",
    "\n",
    "    print 'TODO: VIZ THE F1S'\n",
    "\n",
    "    \n",
    "    res = {'precisions':precisions, 'recalls':recalls, 'f1s':f1s}\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def true_positive_rate(pred, ref):\n",
    "    tp,fn = 0,0\n",
    "    for p,r in zip(pred,ref):\n",
    "        if p==1 and r==1:\n",
    "            tp += 1\n",
    "        elif p==0 and r==1:\n",
    "            fn += 1\n",
    "    return tp / (tp + fn + 1e-9)\n",
    "\n",
    "\n",
    "def false_positive_rate(pred, ref):\n",
    "    fp,tn = 0,0\n",
    "    for p,r in zip(pred,ref):\n",
    "        if p==1 and r==0:\n",
    "            fp += 1\n",
    "        elif p==0 and r==0:\n",
    "            tn += 1\n",
    "    return fp / (fp + tn + 1e-9)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def classification_results(svm, labels_map, X, Y, task, verbose=True):\n",
    "\n",
    "    # for AUC\n",
    "    P_ = svm.decision_function(X)\n",
    "\n",
    "    # sklearn has stupid-ass changes in API when doing binary classification. make it conform to 3+\n",
    "    if len(labels_map)==2:\n",
    "        m = X.shape[0]\n",
    "        P = np.zeros((m,2))\n",
    "        P[:,0] = -P_\n",
    "        P[:,1] =  P_\n",
    "    else:\n",
    "        P = P_\n",
    "\n",
    "    train_pred = P.argmax(axis=1)\n",
    "\n",
    "    # what is the predicted vocab without the dummy label?\n",
    "    V = labels_map.keys()\n",
    "\n",
    "    if verbose: print task\n",
    "    res = compute_stats(task, train_pred, P, Y, labels_map, verbose)\n",
    "    if verbose: print '\\n'\n",
    "    return res\n",
    "    \n",
    "\n",
    "\n",
    "def regression_results(lr, test_X, test_Y, description, verbose=True):\n",
    "    res = {}\n",
    "    \n",
    "    pred_Y = lr.predict(test_X)\n",
    "    res['rms'] = sqrt(mean_squared_error(test_Y, pred_Y))\n",
    "    res['mas'] = mean_absolute_error(test_Y, pred_Y)\n",
    "    if verbose:\n",
    "        print description\n",
    "        print '\\tRMS:', res['rms']\n",
    "        print '\\tMAS:', res['mas']\n",
    "        print\n",
    "    \n",
    "        fig = plt.figure()\n",
    "        perfect = np.arange(min(test_Y),max(test_Y),100)\n",
    "        plt.scatter(perfect, perfect, color='red', s=0.01)\n",
    "        plt.scatter(test_Y , pred_Y, color='blue', s=1)\n",
    "        plt.xlabel('actual')\n",
    "        plt.ylabel('prediction')\n",
    "        plt.show()\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noncompliant: 54510\n",
      "autopsy: 54510\n",
      "sentiment: 52726\n"
     ]
    }
   ],
   "source": [
    "# Load features\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "def normalize(scores):\n",
    "    vals = np.array(scores.values())\n",
    "    mu = vals.mean()\n",
    "    std = vals.std()\n",
    "    return { k:(v-mu)/std for k,v in scores.items()}\n",
    "\n",
    "\n",
    "# query for insurance info\n",
    "insurance_query = 'SELECT distinct hadm_id,insurance FROM mimiciii.admissions'\n",
    "insurance = pd.read_sql_query(insurance_query, con)\n",
    "\n",
    "# query for oasis info\n",
    "oasis_query = 'SELECT distinct hadm_id,oasis FROM mimiciii.oasis'\n",
    "oasis = pd.read_sql_query(oasis_query, con)\n",
    "\n",
    "# query for demographics info\n",
    "patients_query = 'SELECT distinct hadm_id,gender,age,ethnicity,admission_type,los_hospital FROM mimiciii.icustay_detail'\n",
    "patients = pd.read_sql_query(patients_query, con)\n",
    "patients = patients.loc[patients['admission_type']!='NEWBORN']\n",
    "\n",
    "# Load trust scores\n",
    "with open('../data/mistrust_noncompliant.pkl', 'rb') as f:\n",
    "    noncompliant_dict = normalize(pickle.load(f))\n",
    "print 'noncompliant:', len(noncompliant_dict)\n",
    "noncompliant_df = pd.DataFrame(noncompliant_dict.items(), columns=['hadm_id','noncompliant'])\n",
    "\n",
    "# Load trust scores\n",
    "with open('../data/mistrust_autopsy.pkl', 'rb') as f:\n",
    "    autopsy_dict = normalize(pickle.load(f))\n",
    "print 'autopsy:', len(autopsy_dict)\n",
    "autopsy_df = pd.DataFrame(autopsy_dict.items(), columns=['hadm_id','autopsy'])\n",
    "\n",
    "# Load trust scores\n",
    "with open('../data/neg_sentiment.pkl', 'rb') as f:\n",
    "    sentiment_dict = normalize(pickle.load(f))\n",
    "print 'sentiment:', len(sentiment_dict)\n",
    "sentiment_df = pd.DataFrame(sentiment_dict.items(), columns=['hadm_id','sentiment'])\n",
    "\n",
    "    \n",
    "# merge data\n",
    "extra_1 = pd.merge(insurance, oasis, on=['hadm_id'])\n",
    "extra_2 = pd.merge(extra_1, noncompliant_df, on=['hadm_id'])\n",
    "extra_3 = pd.merge(extra_2, autopsy_df     , on=['hadm_id'])\n",
    "extra_4 = pd.merge(extra_3, sentiment_df   , on=['hadm_id'])\n",
    "demographics = pd.merge(extra_4, patients  , on=['hadm_id'])\n",
    "\n",
    "# Normalize some columns\n",
    "demographics['ethnicity'] = demographics['ethnicity'].apply(normalize_race)\n",
    "demographics['insurance'] = demographics['insurance'].apply(normalize_insurance)\n",
    "demographics = demographics.rename(columns={'ethnicity':'race'})\n",
    "demographics = demographics.rename(columns={'los_hospital':'los'})\n",
    "\n",
    "#demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-04 23:55:40\n",
      "2019-01-04 23:55:40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def normalize_mean_std(value, mu, std):\n",
    "    return (value-mu)/std\n",
    "    \n",
    "# normalize ages\n",
    "ages = np.array(demographics['age'])\n",
    "age_mu = ages.mean()\n",
    "age_std = ages.std()\n",
    "demographics['age'] = demographics['age'].apply(lambda val:normalize_mean_std(val,age_mu,age_std))\n",
    "\n",
    "# normalize oasis scores\n",
    "oasis = np.array(demographics['oasis'])\n",
    "oasis_mu = oasis.mean()\n",
    "oasis_std = oasis.std()\n",
    "demographics['oasis'] = demographics['oasis'].apply(lambda val:normalize_mean_std(val,oasis_mu,oasis_std))\n",
    "\n",
    "# normalize los scores\n",
    "los = np.array(demographics['los'])\n",
    "los_mu = los.mean()\n",
    "los_std = los.std()\n",
    "demographics['los'] = demographics['los'].apply(lambda val:normalize_mean_std(val,los_mu,los_std))\n",
    "\n",
    "# foo\n",
    "\n",
    "def build_features(enabled):\n",
    "    demographics_features = {}\n",
    "    for i,row in tqdm.tqdm(demographics.iterrows()):\n",
    "        feats = {}\n",
    "\n",
    "        if 'admission_type' in enabled: feats[('admission_type', row.admission_type   )] = 1\n",
    "        if 'oasis'          in enabled: feats[('oasis', None)] = row.oasis\n",
    "\n",
    "        if 'age' in enabled: feats[('age'  , None)] = row.age\n",
    "        if 'los' in enabled: feats[('los'  , None)] = row.los\n",
    "\n",
    "        if 'insurance' in enabled: feats[('insurance'     , row.insurance)] = 1\n",
    "        if 'gender'    in enabled: feats[('gender'        , row.gender   )] = 1\n",
    "\n",
    "        if 'race'     in enabled: feats[('race', row.race     )] = 1\n",
    "            \n",
    "        if 'noncompliant' in enabled: feats[('concompliant',None)] = row.noncompliant\n",
    "        if 'autopsy'      in enabled: feats[('autopsy'     ,None)] = row.autopsy\n",
    "        if 'sentiment'    in enabled: feats[('sentiment'   ,None)] = row.sentiment\n",
    "\n",
    "        demographics_features[row.hadm_id] = feats\n",
    "\n",
    "    print strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # fit vectorizer\n",
    "    vect = DictVectorizer()\n",
    "    vect.fit(demographics_features.values())\n",
    "    print 'num_features:', len(vect.get_feature_names())\n",
    "\n",
    "    # ordering of all features\n",
    "    ids = demographics_features.keys()\n",
    "    print '\\t', strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    X = vect.transform([demographics_features[hadm_id] for hadm_id in ids])    \n",
    "\n",
    "    return demographics_features, vect\n",
    "    \n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [00:00, 1558.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-04 23:55:43\n",
      "BASELINE+ALL\n",
      "['age', 'los', 'insurance', 'gender', 'race', 'noncompliant', 'autopsy', 'sentiment']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50976it [00:11, 4621.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-04 23:55:54\n",
      "num_features: 16\n",
      "\t2019-01-04 23:55:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients: 47543\n",
      "Counter({0: 47245, 1: 298})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/wboag/2019/cleanup/venv_2/local/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "100%|██████████| 100/100 [00:58<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCS:  [0.89085836 0.87451773 0.86329029 0.88408219 0.89035107 0.87634156\n",
      " 0.85361896 0.88157711 0.88065734 0.86516597 0.86856116 0.88300858\n",
      " 0.88137883 0.88320671 0.88812047 0.88007833 0.88230375 0.87829285\n",
      " 0.8748245  0.91639247 0.89264881 0.89115691 0.87476056 0.85905941\n",
      " 0.87554156 0.85732955 0.88284435 0.85839766 0.8799578  0.86908893\n",
      " 0.89174152 0.86671688 0.88220822 0.87732697 0.88030455 0.89137241\n",
      " 0.8867698  0.86312367 0.85721262 0.86575462 0.88775139 0.85696205\n",
      " 0.87613734 0.87202482 0.8802392  0.90086206 0.85793807 0.86521937\n",
      " 0.89495269 0.8658927  0.87831191 0.86941768 0.87711767 0.88482268\n",
      " 0.87855656 0.88983952 0.89751318 0.8847497  0.85721101 0.88421151\n",
      " 0.87548531 0.88819443 0.86884018 0.84322693 0.88361441 0.8869534\n",
      " 0.87567408 0.85618495 0.88431146 0.88122912 0.86976073 0.89480167\n",
      " 0.87060475 0.86481452 0.88576387 0.89274246 0.87193027 0.85798495\n",
      " 0.87003016 0.86079918 0.87679576 0.87799497 0.89582342 0.86226321\n",
      " 0.89043775 0.88136813 0.86984861 0.87225548 0.8670835  0.88317805\n",
      " 0.86866637 0.8519804  0.89656436 0.86502672 0.88291854 0.87050002\n",
      " 0.88829886 0.88085863 0.88013883 0.90887855]\n",
      "    mean:      0.877135031166653\n",
      "    1.96*std:  0.025179069286409592\n",
      "    conf_interval: (0.8520,0.9023)\n",
      "ama\n",
      "\t('concompliant', None)   :  0.6774\n",
      "\t('sentiment', None)      :  0.1296\n",
      "\t('race', 'Black')        :  0.0850\n",
      "\t('race', 'White')        :  0.0000\n",
      "\t('race', 'Native American'):  0.0000\n",
      "\t('race', 'Hispanic')     :  0.0000\n",
      "\t('race', 'Asian')        :  0.0000\n",
      "\t('insurance', 'Self Pay'):  0.0000\n",
      "\t('insurance', 'Public')  :  0.0000\n",
      "\t('gender', 'M')          :  0.0000\n",
      "\t('autopsy', None)        :  0.0000\n",
      "\t('race', 'Other')        : -0.0673\n",
      "\t('gender', 'F')          : -0.3856\n",
      "\t('insurance', 'Private') : -0.9145\n",
      "\t('los', None)            : -1.1376\n",
      "\t('age', None)            : -1.9662\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "age       :None            || -2.01 +/- 0.27\n",
      "autopsy   :None            || 0.02 +/- 0.07\n",
      "concompliant:None            || 0.67 +/- 0.08\n",
      "gender    :F               || -0.37 +/- 0.18\n",
      "gender    :M               || 0.00 +/- 0.00\n",
      "insurance :Private         || -1.04 +/- 0.20\n",
      "insurance :Public          || 0.00 +/- 0.00\n",
      "insurance :Self Pay        || 0.00 +/- 0.00\n",
      "los       :None            || -1.29 +/- 0.28\n",
      "race      :Asian           || 0.00 +/- 0.00\n",
      "race      :Black           || 0.05 +/- 0.17\n",
      "race      :Hispanic        || 0.00 +/- 0.00\n",
      "race      :Native American || 0.00 +/- 0.00\n",
      "race      :Other           || -0.14 +/- 0.22\n",
      "race      :White           || -0.03 +/- 0.10\n",
      "sentiment :None            || 0.11 +/- 0.07\n",
      "2019-01-04 23:56:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# AMA\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "featlists = {\n",
    "                #'BASELINE'             :['age', 'los', 'insurance', 'gender'],\n",
    "                #'BASELINE+RACE'        :['age', 'los', 'insurance', 'gender', 'race'],\n",
    "                #'BASELINE+NONCOMPLIANT':['age', 'los', 'insurance', 'gender', 'noncompliant'],\n",
    "                #'BASELINE+AUTOPSY'     :['age', 'los', 'insurance', 'gender', 'autopsy'],\n",
    "                #'BASELINE+SENTIMENT'   :['age', 'los', 'insurance', 'gender', 'sentiment'],\n",
    "                'BASELINE+ALL'         :['age', 'los', 'insurance', 'gender', 'race', 'noncompliant', 'autopsy', 'sentiment']\n",
    "            }\n",
    "\n",
    "ama_Y_vect = {'AMA': 1, 'compliant': 0}\n",
    "\n",
    "feature_weights = defaultdict(list)\n",
    "\n",
    "for name,featlist in featlists.items():\n",
    "    print name\n",
    "    print featlist\n",
    "    \n",
    "    demographics_features, vect = build_features(featlist)\n",
    "    ind2feat =  { i:f for f,i in vect.vocabulary_.items() }\n",
    "\n",
    "    ama_ids = list(set(discharge['hadm_id'].values) & set(demographics_features.keys()))\n",
    "    print 'patients:', len(ama_ids)\n",
    "  \n",
    "    print Counter([ama_Y_vect[ama_labels[hadm_id]] for hadm_id in ama_ids])\n",
    "\n",
    "    aucs = []\n",
    "    for iteration in tqdm.tqdm(range(100)):\n",
    "\n",
    "        # train/test split\n",
    "        ama_train_ids, ama_test_ids = data_split(ama_ids)\n",
    "\n",
    "        # select pre-computed features\n",
    "        ama_train_features = [demographics_features[hadm_id] for hadm_id in ama_train_ids]\n",
    "        ama_test_features  = [demographics_features[hadm_id] for hadm_id in ama_test_ids ]\n",
    "\n",
    "        # vectorize features\n",
    "        ama_train_X = vect.transform(ama_train_features)\n",
    "        ama_test_X  = vect.transform(ama_test_features)\n",
    "\n",
    "        # vectorize task-specific labels\n",
    "        #print ama_Y_vect\n",
    "\n",
    "        # select labels\n",
    "        ama_train_Y = [ama_Y_vect[ama_labels[hadm_id]] for hadm_id in ama_train_ids]\n",
    "        ama_test_Y  = [ama_Y_vect[ama_labels[hadm_id]] for hadm_id in ama_test_ids ]\n",
    "\n",
    "        # fit model\n",
    "        ama_svm = LogisticRegression(C=0.1, penalty='l1', tol=0.01)\n",
    "        ama_svm.fit(ama_train_X,ama_train_Y)\n",
    "        #print ama_svm\n",
    "\n",
    "\n",
    "        # AMA Model eval\n",
    "\n",
    "        # evaluate model\n",
    "        res = classification_results(ama_svm, ama_Y_vect,  ama_test_X,  ama_test_Y, 'test:  ama', verbose=False)\n",
    "        aucs.append(res['auc'])\n",
    "\n",
    "        # record the weights of the features (because we average them)\n",
    "        if name == 'BASELINE+ALL':\n",
    "            for feat,val in enumerate(ama_svm.coef_.tolist()[0]):\n",
    "                featname = ind2feat[feat]\n",
    "                feature_weights[featname].append(val)\n",
    "\n",
    "        #classification_results(ama_svm, ama_Y_vect, ama_train_X, ama_train_Y, 'train: ama')\n",
    "\n",
    "    aucs = np.array(aucs)\n",
    "    print 'AUCS: ', aucs\n",
    "    print '    mean:     ', aucs.mean()\n",
    "    print '    1.96*std: ', aucs.std() * 1.96\n",
    "    print '    conf_interval: (%.4f,%.4f)' % (aucs.mean()-1.96*aucs.std(),aucs.mean()+1.96*aucs.std())\n",
    "\n",
    "\n",
    "    # most informative features\n",
    "    analyze('ama', vect, ama_svm)\n",
    "    print '\\n\\n\\n'\n",
    "\n",
    "    if name == 'BASELINE+ALL':\n",
    "        for featname,vals in sorted(feature_weights.items()):\n",
    "            v = np.array(vals)\n",
    "            mu = v.mean()\n",
    "            std = v.std()\n",
    "            print '%-10s:%-15s || %.2f +/- %.2f' % (featname[0],featname[1],mu,1.96*std)\n",
    "\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-04 23:56:54\n",
      "BASELINE+ALL\n",
      "['age', 'los', 'insurance', 'gender', 'race', 'noncompliant', 'autopsy', 'sentiment']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50976it [00:09, 5236.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-04 23:57:03\n",
      "num_features: 16\n",
      "\t2019-01-04 23:57:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ('age', None), 1: ('autopsy', None), 2: ('concompliant', None), 3: ('gender', 'F'), 4: ('gender', 'M'), 5: ('insurance', 'Private'), 6: ('insurance', 'Public'), 7: ('insurance', 'Self Pay'), 8: ('los', None), 9: ('race', 'Asian'), 10: ('race', 'Black'), 11: ('race', 'Hispanic'), 12: ('race', 'Native American'), 13: ('race', 'Other'), 14: ('race', 'White'), 15: ('sentiment', None)}\n",
      "patients: 39125\n",
      "Counter({0: 36667, 1: 2458})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:56<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCS:  [0.7797595  0.7864562  0.79014992 0.77520486 0.78525847 0.77857338\n",
      " 0.78509857 0.7884304  0.79088733 0.78313686 0.78970985 0.78382875\n",
      " 0.78810281 0.78749812 0.78864029 0.79968577 0.79118141 0.7766818\n",
      " 0.78442367 0.79835093 0.79320046 0.78782693 0.77922702 0.77785324\n",
      " 0.77653062 0.7739758  0.77545866 0.78683858 0.78426325 0.79146758\n",
      " 0.78851617 0.78034419 0.78179609 0.78053583 0.79187255 0.77957677\n",
      " 0.77715471 0.78672934 0.78565199 0.78691719 0.7823756  0.79901502\n",
      " 0.78399456 0.79059203 0.78916896 0.78086252 0.78317603 0.789163\n",
      " 0.77354958 0.7843122  0.78671648 0.78893047 0.78814728 0.79108546\n",
      " 0.78363495 0.78281243 0.78065414 0.78432409 0.78813066 0.79278352\n",
      " 0.7875232  0.7914536  0.78602473 0.78989935 0.78689736 0.78563218\n",
      " 0.77992618 0.78788532 0.7715448  0.77773195 0.78589674 0.7889953\n",
      " 0.77955621 0.78865128 0.77682282 0.78573882 0.79123264 0.79180179\n",
      " 0.79263443 0.78321795 0.77307465 0.78996017 0.7806325  0.78791611\n",
      " 0.77808487 0.78548196 0.78705411 0.79317152 0.7917187  0.78726033\n",
      " 0.78452652 0.78974519 0.79713672 0.78700532 0.7865117  0.77649573\n",
      " 0.77931047 0.77447012 0.79025335 0.77635024]\n",
      "    mean:      0.7852545173158318\n",
      "    1.96*std:  0.011679984538350854\n",
      "    conf_interval: (0.7736,0.7969)\n",
      "cs\n",
      "\t('age', None)            :  0.4279\n",
      "\t('sentiment', None)      :  0.2273\n",
      "\t('concompliant', None)   :  0.1231\n",
      "\t('race', 'White')        :  0.0523\n",
      "\t('race', 'Native American'):  0.0000\n",
      "\t('race', 'Asian')        :  0.0000\n",
      "\t('insurance', 'Self Pay'):  0.0000\n",
      "\t('insurance', 'Public')  :  0.0000\n",
      "\t('gender', 'F')          :  0.0000\n",
      "\t('race', 'Other')        : -0.2210\n",
      "\t('gender', 'M')          : -0.2419\n",
      "\t('race', 'Hispanic')     : -0.2592\n",
      "\t('race', 'Black')        : -0.3358\n",
      "\t('autopsy', None)        : -0.4205\n",
      "\t('los', None)            : -0.7181\n",
      "\t('insurance', 'Private') : -0.9016\n",
      "age       :None            || 0.42 +/- 0.02\n",
      "autopsy   :None            || -0.39 +/- 0.05\n",
      "concompliant:None            || 0.15 +/- 0.03\n",
      "gender    :F               || -0.54 +/- 1.36\n",
      "gender    :M               || -0.85 +/- 1.37\n",
      "insurance :Private         || -0.95 +/- 0.51\n",
      "insurance :Public          || -0.06 +/- 0.48\n",
      "insurance :Self Pay        || -0.04 +/- 0.35\n",
      "los       :None            || -0.68 +/- 0.09\n",
      "race      :Asian           || 0.00 +/- 0.00\n",
      "race      :Black           || -0.21 +/- 0.21\n",
      "race      :Hispanic        || -0.20 +/- 0.24\n",
      "race      :Native American || 0.00 +/- 0.00\n",
      "race      :Other           || -0.15 +/- 0.19\n",
      "race      :White           || 0.07 +/- 0.17\n",
      "sentiment :None            || 0.22 +/- 0.03\n",
      "2019-01-04 23:58:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Code Status\n",
    "\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "featlists = {\n",
    "                #'BASELINE'             :['age', 'los', 'insurance', 'gender'],\n",
    "                #'BASELINE+RACE'        :['age', 'los', 'insurance', 'gender', 'race'],\n",
    "                #'BASELINE+NONCOMPLIANT':['age', 'los', 'insurance', 'gender', 'noncompliant'],\n",
    "                #'BASELINE+AUTOPSY'     :['age', 'los', 'insurance', 'gender', 'autopsy'],\n",
    "                #'BASELINE+SENTIMENT'   :['age', 'los', 'insurance', 'gender', 'sentiment'],\n",
    "                'BASELINE+ALL'         :['age', 'los', 'insurance', 'gender', 'race', 'noncompliant', 'autopsy', 'sentiment']\n",
    "            }\n",
    "\n",
    "cs_Y_vect = {'DNR/CMO': 1, 'Full Code': 0}\n",
    "\n",
    "feature_weights = defaultdict(list)\n",
    "\n",
    "for name,featlist in featlists.items():\n",
    "    print name\n",
    "    print featlist\n",
    "    \n",
    "    demographics_features, vect = build_features(featlist)\n",
    "    ind2feat =  { i:f for f,i in vect.vocabulary_.items() }\n",
    "    \n",
    "    print ind2feat\n",
    "\n",
    "    cs_ids = list(set(code_labels.keys()) & set(demographics_features.keys()))\n",
    "    print 'patients:', len(cs_ids)\n",
    "    \n",
    "    print Counter([cs_Y_vect[code_labels[hadm_id]] for hadm_id in cs_ids])\n",
    "\n",
    "    \n",
    "    aucs = []\n",
    "    for iteration in tqdm.tqdm(range(100)):\n",
    "\n",
    "        #print 'Iter:', iteration\n",
    "\n",
    "        # train/test split\n",
    "        cs_train_ids, cs_test_ids = data_split(cs_ids)\n",
    "\n",
    "        # select pre-computed features\n",
    "        cs_train_features = [demographics_features[hadm_id] for hadm_id in cs_train_ids]\n",
    "        cs_test_features  = [demographics_features[hadm_id] for hadm_id in cs_test_ids ]\n",
    "\n",
    "        # vectorize features\n",
    "        cs_train_X = vect.transform(cs_train_features)\n",
    "        cs_test_X  = vect.transform(cs_test_features)\n",
    "\n",
    "        # vectorize task-specific labels\n",
    "        cs_Y_vect = {'DNR/CMO': 1, 'Full Code': 0}\n",
    "        #print cs_Y_vect\n",
    "\n",
    "        # select labels\n",
    "        cs_train_Y = [cs_Y_vect[code_labels[hadm_id]] for hadm_id in cs_train_ids]\n",
    "        cs_test_Y  = [cs_Y_vect[code_labels[hadm_id]] for hadm_id in cs_test_ids ]\n",
    "\n",
    "        # fit model\n",
    "        cs_svm = LogisticRegression(C=0.1, penalty='l1', tol=0.01)\n",
    "        cs_svm.fit(cs_train_X,cs_train_Y)\n",
    "        #print cs_svm\n",
    "\n",
    "\n",
    "        # cs Model eval\n",
    "\n",
    "        # evaluate model\n",
    "        res = classification_results(cs_svm, cs_Y_vect, cs_test_X,  cs_test_Y, 'test:  cs', verbose=False)\n",
    "        aucs.append(res['auc'])\n",
    "\n",
    "        # record the weights of the features (because we average them)\n",
    "        if name == 'BASELINE+ALL':\n",
    "            for feat,val in enumerate(cs_svm.coef_.tolist()[0]):\n",
    "                featname = ind2feat[feat]\n",
    "                feature_weights[featname].append(val)\n",
    "            \n",
    "        # most informative features\n",
    "        #analyze('cs', vect, cs_svm)\n",
    "        \n",
    "    aucs = np.array(aucs)\n",
    "    print 'AUCS: ', aucs\n",
    "    print '    mean:     ', aucs.mean()\n",
    "    print '    1.96*std: ', aucs.std() * 1.96\n",
    "    print '    conf_interval: (%.4f,%.4f)' % (aucs.mean()-1.96*aucs.std(),aucs.mean()+1.96*aucs.std())\n",
    "\n",
    "\n",
    "    # most informative features\n",
    "    analyze('cs', vect, cs_svm)\n",
    "\n",
    "    if name == 'BASELINE+ALL':\n",
    "        for featname,vals in sorted(feature_weights.items()):\n",
    "            v = np.array(vals)\n",
    "            mu = v.mean()\n",
    "            std = v.std()\n",
    "            print '%-10s:%-15s || %.2f +/- %.2f' % (featname[0],featname[1],mu,1.96*std)\n",
    "    \n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-04 23:58:01\n",
      "BASELINE+ALL\n",
      "['age', 'los', 'insurance', 'gender', 'race', 'noncompliant', 'autopsy', 'sentiment']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50976it [00:09, 5101.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-04 23:58:11\n",
      "num_features: 16\n",
      "\t2019-01-04 23:58:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patients: 47543\n",
      "Counter({0: 42429, 1: 5114})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:04<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCS:  [0.67597942 0.66796189 0.68214396 0.66944476 0.67395821 0.67354888\n",
      " 0.67068775 0.67290468 0.66699559 0.66895833 0.67467822 0.67241983\n",
      " 0.67598472 0.67080436 0.67627854 0.67294662 0.67546048 0.66784427\n",
      " 0.66833621 0.67154392 0.67297642 0.68192794 0.67203645 0.67081948\n",
      " 0.66367444 0.67145488 0.6727461  0.66890287 0.66642047 0.67044154\n",
      " 0.66952413 0.66924098 0.67655431 0.67170851 0.66759812 0.67527588\n",
      " 0.67156593 0.68010592 0.67829128 0.67254243 0.66715664 0.67592364\n",
      " 0.6731543  0.6670147  0.66636753 0.6692419  0.68142159 0.67192896\n",
      " 0.67877901 0.67566752 0.66671362 0.67740352 0.67710221 0.67190979\n",
      " 0.67630895 0.67681584 0.67535052 0.67356308 0.67016684 0.66646245\n",
      " 0.68222291 0.67226293 0.67685544 0.66950803 0.66685135 0.67073491\n",
      " 0.67617529 0.66689762 0.66978465 0.66456813 0.67865127 0.67193433\n",
      " 0.67314576 0.67493967 0.67532346 0.66796884 0.67105338 0.66678113\n",
      " 0.66869323 0.66587796 0.66838179 0.67589294 0.66866678 0.66446579\n",
      " 0.66724467 0.66733614 0.67077739 0.67085804 0.67256763 0.66913873\n",
      " 0.67406352 0.67361099 0.66233203 0.67822279 0.67317808 0.67341739\n",
      " 0.68405346 0.67798918 0.67584375 0.67465235]\n",
      "    mean:      0.672240650765642\n",
      "    1.96*std:  0.008758308603712482\n",
      "    conf_interval: (0.6635,0.6810)\n",
      "mortality\n",
      "\t('sentiment', None)      :  0.4068\n",
      "\t('race', 'Other')        :  0.2301\n",
      "\t('age', None)            :  0.2248\n",
      "\t('concompliant', None)   :  0.0857\n",
      "\t('autopsy', None)        :  0.0408\n",
      "\t('los', None)            :  0.0304\n",
      "\t('race', 'Native American'):  0.0000\n",
      "\t('race', 'Asian')        :  0.0000\n",
      "\t('insurance', 'Self Pay'):  0.0000\n",
      "\t('insurance', 'Public')  :  0.0000\n",
      "\t('race', 'White')        : -0.1712\n",
      "\t('insurance', 'Private') : -0.3596\n",
      "\t('race', 'Black')        : -0.5109\n",
      "\t('race', 'Hispanic')     : -0.5461\n",
      "\t('gender', 'F')          : -1.6726\n",
      "\t('gender', 'M')          : -1.6828\n",
      "age       :None            || 0.21 +/- 0.02\n",
      "autopsy   :None            || 0.04 +/- 0.03\n",
      "concompliant:None            || 0.09 +/- 0.03\n",
      "gender    :F               || -0.75 +/- 1.06\n",
      "gender    :M               || -0.80 +/- 1.05\n",
      "insurance :Private         || -0.81 +/- 0.89\n",
      "insurance :Public          || -0.45 +/- 0.90\n",
      "insurance :Self Pay        || -0.13 +/- 0.59\n",
      "los       :None            || 0.05 +/- 0.03\n",
      "race      :Asian           || -0.04 +/- 0.14\n",
      "race      :Black           || -0.54 +/- 0.30\n",
      "race      :Hispanic        || -0.62 +/- 0.35\n",
      "race      :Native American || 0.00 +/- 0.00\n",
      "race      :Other           || 0.15 +/- 0.31\n",
      "race      :White           || -0.26 +/- 0.29\n",
      "sentiment :None            || 0.41 +/- 0.03\n",
      "\n",
      "\n",
      "\n",
      "2019-01-04 23:59:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Mortality\n",
    "\n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "featlists = {\n",
    "                #'BASELINE'             :['age', 'los', 'insurance', 'gender'],\n",
    "                #'BASELINE+RACE'        :['age', 'los', 'insurance', 'gender', 'race'],\n",
    "                #'BASELINE+NONCOMPLIANT':['age', 'los', 'insurance', 'gender', 'noncompliant'],\n",
    "                #'BASELINE+AUTOPSY'     :['age', 'los', 'insurance', 'gender', 'autopsy'],\n",
    "                #'BASELINE+SENTIMENT'   :['age', 'los', 'insurance', 'gender', 'sentiment'],\n",
    "                'BASELINE+ALL'         :['age', 'los', 'insurance', 'gender', 'race', 'noncompliant', 'autopsy', 'sentiment']\n",
    "            }\n",
    "mortality_Y_vect = {'deceased': 1, 'survived': 0}\n",
    "\n",
    "feature_weights = defaultdict(list)\n",
    "\n",
    "\n",
    "for name,featlist in featlists.items():\n",
    "    print name\n",
    "    print featlist\n",
    "    \n",
    "    demographics_features, vect = build_features(featlist)\n",
    "    ind2feat =  { i:f for f,i in vect.vocabulary_.items() }\n",
    "\n",
    "    mortality_ids = list(set(mortality_labels.keys()) & set(demographics_features.keys()))\n",
    "    print 'patients:', len(mortality_ids)\n",
    "    \n",
    "    print Counter([mortality_Y_vect[mortality_labels[hadm_id]] for hadm_id in mortality_ids])\n",
    "\n",
    "    aucs = []\n",
    "    for iteration in tqdm.tqdm(range(100)):\n",
    "\n",
    "        #print 'Iter:', iteration\n",
    "\n",
    "\n",
    "        # train/test split\n",
    "        mortality_train_ids, mortality_test_ids = data_split(mortality_ids)\n",
    "\n",
    "        # select pre-computed features\n",
    "        mortality_train_features = [demographics_features[hadm_id] for hadm_id in mortality_train_ids]\n",
    "        mortality_test_features  = [demographics_features[hadm_id] for hadm_id in mortality_test_ids ]\n",
    "\n",
    "        # vectorize features\n",
    "        mortality_train_X = vect.transform(mortality_train_features)\n",
    "        mortality_test_X  = vect.transform(mortality_test_features)\n",
    "\n",
    "        # vectorize task-specific labels\n",
    "        #print mortality_Y_vect\n",
    "\n",
    "        # select labels\n",
    "        mortality_train_Y = [mortality_Y_vect[mortality_labels[hadm_id]] for hadm_id in mortality_train_ids]\n",
    "        mortality_test_Y  = [mortality_Y_vect[mortality_labels[hadm_id]] for hadm_id in mortality_test_ids ]\n",
    "\n",
    "        # fit model\n",
    "        mortality_svm = LogisticRegression(C=0.1, penalty='l1', tol=0.01)\n",
    "        mortality_svm.fit(mortality_train_X,mortality_train_Y)\n",
    "        #print mortality_svm\n",
    "\n",
    "\n",
    "        # mortality Model eval\n",
    "\n",
    "        # evaluate model\n",
    "        res = classification_results(mortality_svm, mortality_Y_vect, mortality_test_X, mortality_test_Y, 'test:  mortality', verbose=False)\n",
    "        aucs.append(res['auc'])\n",
    "\n",
    "        # record the weights of the features (because we average them)\n",
    "        if name == 'BASELINE+ALL':\n",
    "            for feat,val in enumerate(mortality_svm.coef_.tolist()[0]):\n",
    "                featname = ind2feat[feat]\n",
    "                feature_weights[featname].append(val)\n",
    "            \n",
    "        # most informative features\n",
    "        #analyze('mortality', vect, mortality_svm)\n",
    "        \n",
    "    aucs = np.array(aucs)\n",
    "    print 'AUCS: ', aucs\n",
    "    print '    mean:     ', aucs.mean()\n",
    "    print '    1.96*std: ', aucs.std() * 1.96\n",
    "    print '    conf_interval: (%.4f,%.4f)' % (aucs.mean()-1.96*aucs.std(),aucs.mean()+1.96*aucs.std())\n",
    "\n",
    "\n",
    "    # most informative features\n",
    "    analyze('mortality', vect, mortality_svm)\n",
    "\n",
    "    # foo\n",
    "\n",
    "\n",
    "    if name == 'BASELINE+ALL':\n",
    "        for featname,vals in sorted(feature_weights.items()):\n",
    "            v = np.array(vals)\n",
    "            mu = v.mean()\n",
    "            std = v.std()\n",
    "            print '%-10s:%-15s || %.2f +/- %.2f' % (featname[0],featname[1],mu,1.96*std)\n",
    "            \n",
    "    print '\\n\\n'\n",
    "    \n",
    "print strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autopsy\n",
      "\tmost  trust 0.13357775318206974\n",
      "\tleast trust 0.09118384195783577\n",
      "noncompliant\n",
      "\tmost  trust 0.04738502163867087\n",
      "\tleast trust 0.12881658123467796\n",
      "sentiment\n",
      "\tmost  trust 0.04483386436049158\n",
      "\tleast trust 0.16614824368409073\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = {'noncompliant':noncompliant_dict, 'autopsy':autopsy_dict, 'sentiment':sentiment_dict}\n",
    "\n",
    "for metric,scores in metrics.items():\n",
    "    print metric\n",
    "\n",
    "    vals = sorted(scores.values())\n",
    "    n = len(vals)\n",
    "    t1 = vals[1*n/4]\n",
    "    t2 = vals[2*n/4]\n",
    "    t3 = vals[3*n/4]\n",
    "\n",
    "    lowest  = [hadm_id for hadm_id,score in scores.items() if     score<=t1]\n",
    "    highest = [hadm_id for hadm_id,score in scores.items() if t3< score    ]\n",
    "\n",
    "    def mort_rate(label, hadm_ids):\n",
    "        cohort = mortality.loc[mortality['hadm_id'].isin(hadm_ids)]\n",
    "        print '\\t', label, sum(cohort['hospital_expire_flag'].values)/float(len(cohort))\n",
    "\n",
    "    mort_rate('most  trust', lowest)\n",
    "    mort_rate('least trust', highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
